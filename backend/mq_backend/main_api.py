#!/usr/bin/env python
# -*- coding: utf-8 -*-
# ç”¨äºå’ŒrabbitMQè¿›è¡Œäº¤äº’
import os
import random
import string
import time
import json
import asyncio
import traceback
import dotenv
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from mq_handler import start_consumer, MQHandler
from A2Aclient import A2AClientWrapper
dotenv.load_dotenv()


# åˆ›å»ºä¸€ä¸ªçº¿ç¨‹æ± ï¼Œå®šä¹‰çº¿ç¨‹æ± çš„å¤§å°10
executor = ThreadPoolExecutor(max_workers=20)

RABBITMQ_HOST = os.environ["RABBITMQ_HOST"]
RABBITMQ_PORT = os.environ["RABBITMQ_PORT"]
RABBITMQ_USERNAME = os.environ["RABBITMQ_USERNAME"]
RABBITMQ_PASSWORD = os.environ["RABBITMQ_PASSWORD"]
RABBITMQ_VIRTUAL_HOST = os.environ["RABBITMQ_VIRTUAL_HOST"]
QUEUE_NAME_ANSWER = os.environ["QUEUE_NAME_ANSWER"]
QUEUE_NAME_QUESTION = os.environ["QUEUE_NAME_QUESTION"]


def handle_reasoning_stream_response(link_id, session_id, user_id, function_id, attachment, stream_response):
    """
    å¤„ç†æ€ç»´é“¾æµå¼å“åº”
    """
    pass


def handle_gpt_stream_response(link_id, session_id, user_id, function_id, attachment, stream_response):
    """
    å¤„ç†GPTæµå¼å“åº”
    """
    mq_handler = MQHandler(RABBITMQ_HOST, RABBITMQ_PORT, RABBITMQ_USERNAME, RABBITMQ_PASSWORD, RABBITMQ_VIRTUAL_HOST,
                           QUEUE_NAME_ANSWER)
    # å¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œå…ˆå¤„ç†é”™è¯¯ï¼šstream_responseæ˜¯å­—ç¬¦ä¸²å°±æ˜¯é”™è¯¯ï¼Œåº”è¯¥é»˜è®¤æ˜¯ç”Ÿæˆå™¨
    def send_error_message(error_msg):
        """å‘é€é”™è¯¯ä¿¡æ¯åˆ°æ¶ˆæ¯é˜Ÿåˆ—"""
        mq_handler.send_message({
            "linkId": link_id,
            "sessionId": session_id,
            "userId": user_id,
            "functionId": function_id,
            "message": f'å‘ç”Ÿé”™è¯¯ï¼š{error_msg}',
            "reasoningMessage": "",
            "attachment": attachment,
            "type": 4,
        })
        time.sleep(0.01)
        mq_handler.send_message({
            "linkId": link_id,
            "sessionId": session_id,
            "userId": user_id,
            "functionId": function_id,
            "message": '[stop]',
            "reasoningMessage": "",
            "attachment": attachment,
            "type": 4,
        })

    if isinstance(stream_response, str):
        send_error_message(stream_response)
        mq_handler.close_connection()
        return
    async def consume():
        try:
            async for chunk in stream_response:
                try:
                    data_type = chunk.get("type")
                    if data_type == "final":
                        answer_queue_message = {
                            "linkId": link_id,
                            "sessionId": session_id,
                            "userId": user_id,
                            "functionId": function_id,
                            "message": '[stop]',
                            "reasoningMessage": "",
                            "attachment": attachment,
                            "type": 4,
                        }
                    elif data_type == "reasoning":
                        answer_queue_message = {
                            "linkId": link_id,
                            "sessionId": session_id,
                            "userId": user_id,
                            "functionId": function_id,
                            "message": '',
                            "reasoningMessage": chunk.get("reasoning", ""),
                            "attachment": attachment,
                            "type": 4,
                        }
                    elif data_type == "text":
                        answer_queue_message = {
                            "linkId": link_id,
                            "sessionId": session_id,
                            "userId": user_id,
                            "functionId": function_id,
                            "message": chunk.get("text", ""),
                            "reasoningMessage": '',
                            "attachment": attachment,
                            "type": 4,
                        }
                    elif data_type == "data":
                        chunk_data = chunk.get("data", {})
                        tools_data = chunk_data.get("data", [])
                        # display_content = "".join(tool.get("display", "") for tool in tools_data)
                        # å‘é€ç»™å‰ç«¯çš„æ•°æ®ï¼Œlistæ ¼å¼ï¼Œé‡Œé¢æ˜¯å­—å…¸
                        front_data = [tool["front_data"] for tool in tools_data]
                        #å·¥å…·æ˜¯è°ƒç”¨è¿˜æ˜¯ç»“æŸäº†ï¼Œåªéœ€è¦å·¥å…·ç»“æŸäº†çš„æ•°æ®
                        tool_type = chunk_data.get("type")
                        answer_queue_message = {
                            "linkId": link_id,
                            "sessionId": session_id,
                            "userId": user_id,
                            "functionId": function_id,
                            "message": json.dumps(front_data, ensure_ascii=False),
                            "reasoningMessage": "",
                            "attachment": attachment,
                            "type": 5,
                        }
                        print(f"[Info] å‘é€çŠ¶æ€æ•°æ®å®Œæˆï¼ˆtype 5)ï¼š{answer_queue_message}")
                        # å‘é€å¼•ç”¨æ•°æ®å’Œå‚è€ƒï¼Œå³åŒ¹é…çš„ç»“æœ
                        if tool_type == "tool_result":
                            tool_retrieve_data = [one.get("data",{}) for one in tools_data]
                            answer_reference = {
                                "linkId": link_id,
                                "sessionId": session_id,
                                "userId": user_id,
                                "functionId": function_id,
                                "message": json.dumps(tool_retrieve_data, ensure_ascii=False),
                                "reasoningMessage": "",
                                "attachment": attachment,
                                "type": 6,
                            }
                            mq_handler.send_message(answer_reference)
                            print(f"[Info] å‘é€å¼•ç”¨å’Œå‚è€ƒæ•°æ®å®Œæˆ(type 6)ï¼š{answer_reference}")
                    else:
                        print(f"[è­¦å‘Š] æœªçŸ¥çš„chunkç±»å‹ï¼š{data_type}ï¼Œå·²è·³è¿‡")
                        continue

                    mq_handler.send_message(answer_queue_message)
                    if function_id not in [5000, 9001]:
                        time.sleep(0.01)
                except Exception as chunk_error:
                    print("[é”™è¯¯] å¤„ç† chunk æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š", chunk_error)
                    traceback.print_exc()
                    send_error_message(f"å¤„ç†æ•°æ®å—å‡ºé”™ï¼š{chunk_error}")
        except Exception as stream_error:
            print("[é”™è¯¯] æµæ¶ˆè´¹å¤±è´¥ï¼š", stream_error)
            traceback.print_exc()
            send_error_message(f"å¤„ç†æµå‡ºé”™ï¼š{stream_error}")
        finally:
            mq_handler.close_connection()

    asyncio.run(consume())


def handle_rabbit_queue_message(rabbit_message):
    """
    å¤„ç†ä»RabbitMQ é˜Ÿåˆ—æ¥æ”¶åˆ°çš„æ¶ˆæ¯
    """
    # è§£æmqæ¶ˆæ¯
    print(f"å¤„ç†æ¶ˆæ¯handle_rabbit_queue_message: {rabbit_message}")
    session_id = rabbit_message['sessionId']
    user_id = rabbit_message['userId']
    function_id = rabbit_message['functionId']
    messages = rabbit_message['messages']
    attachment = rabbit_message['attachment']
    # ç±»å‹ï¼š1.æ–‡æœ¬ 2.å‡½æ•° 3.å¸¦é™„ä»¶çš„æ–‡æœ¬
    queue_message_type = int(rabbit_message['type'])
    # æ˜¯å¦è¦è°ƒç”¨functionï¼Œé»˜è®¤è°ƒç”¨ï¼Œåªæœ‰æ˜ç¡®ä¸æ‰ç”¨æ—¶æ‰ä¸è°ƒç”¨
    call_tools = rabbit_message.get('callTools', True)
    # link_id:å¦‚æœæ²¡æœ‰å¯¹åº”çš„keyï¼Œé»˜è®¤ä¸ºNone
    link_id = rabbit_message.get('linkId', None)

    document_id = 0

    # è°ƒç”¨GPT
    response = None
    stream_response = None
    reasoning_stream_response = None
    stream_response_dify = None
    if function_id == 6:
        # Agent RAGçš„é—®ç­”
        agent_session_id = session_id + ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))
        wrapper = A2AClientWrapper(session_id=agent_session_id, agent_url=AGENT_URL)
        stream_response = wrapper.generate(messages)
    else:
        print('ä¸åœ¨è¿›è¡Œå¤„ç†è¿™æ¡æ¶ˆæ¯ï¼Œfunction_id NOT  : ' + str(function_id))
        return

    if stream_response:
        handle_gpt_stream_response(link_id, session_id, user_id, function_id, attachment, stream_response)
    elif reasoning_stream_response:
        handle_reasoning_stream_response(link_id, session_id, user_id, function_id, attachment,
                                         reasoning_stream_response)


def callback(ch, method, properties, body):
    """
    mqæ¥æ”¶åˆ°æ¶ˆæ¯åçš„å›è°ƒå‡½æ•°ï¼Œå¤šçº¿ç¨‹å¤„ç†
    """
    try:
        # æ¥æ”¶åˆ°mqçš„æ¶ˆæ¯ï¼šè½¬æ¢æˆdict
        print(f"ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ğŸ˜ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        rabbit_message = json.loads(json.loads(body.decode('utf-8')))
        print(f" [ğŸšš] ä»mqæ¥å—åˆ°æ¶ˆæ¯ï¼š{rabbit_message}")
        # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
        executor.submit(handle_rabbit_queue_message, rabbit_message)
        # æ‰‹åŠ¨å‘é€æ¶ˆæ¯ç¡®è®¤
        ch.basic_ack(delivery_tag=method.delivery_tag)
    except Exception as e:
        print(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
        # å‡ºé”™æ—¶æ‹’ç»æ¶ˆæ¯å¹¶é‡æ–°å…¥é˜Ÿ
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)


if __name__ == '__main__':
    start_consumer(callback, auto_ack=False)
